from django.shortcuts import render
from django.http import JsonResponse
from .models import Question
import json
from django.views.decorators.csrf import csrf_exempt


import os
from dotenv import load_dotenv


from openai import OpenAI

import traceback

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


def index(request):
    return render(request, 'polls/index.html')

def chat(request):
    return render(request, 'polls/chat.html')


@csrf_exempt
def get_followup_questions(request):
    if request.method == "POST":
        data = json.loads(request.body)
        category = data.get("category")
        subcategory = data.get("subcategory", "").strip()

        if subcategory:
            questions = Question.objects.filter(
                category=category,
                subcategory=subcategory
            ).order_by("order")
        else:
            questions = Question.objects.filter(
                category=category,
                subcategory=""
            ).order_by("order")

        question_list = [q.text for q in questions]
        return JsonResponse({"questions": question_list})

    return JsonResponse({"error": "POST ìš”ì²­ë§Œ í—ˆìš©ë©ë‹ˆë‹¤."}, status=405)


from django.http import JsonResponse
from django.views.decorators.csrf import csrf_exempt
import os
import json
from openai import OpenAI
from dotenv import load_dotenv
import traceback

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

@csrf_exempt
def process_answers(request):
    if request.method == "POST":
        try:
            data = json.loads(request.body)
            category = data.get("category", "")
            subcategory = data.get("subcategory", "")
            qa_list = data.get("qa", [])

            prompt = f"""
ë‹¹ì‹ ì€ ê°ì • ê¸°ë°˜ ê¸°ì–µ ìƒë‹´ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìëŠ” ì–´ë–¤ ê¸°ì–µì„ ë– ì˜¬ë¦¬ê³  ì‹¶ì–´ í•˜ì§€ë§Œ ìŠ¤ìŠ¤ë¡œ ì˜ ë– ì˜¬ë¦¬ì§€ ëª»í•˜ê³  ìˆìŠµë‹ˆë‹¤.

ì¹´í…Œê³ ë¦¬: {category}
ì„¸ë¶€ ë¶„ë¥˜: {subcategory}

ì§ˆë¬¸-ë‹µë³€ ëª©ë¡:
{json.dumps(qa_list, ensure_ascii=False, indent=2)}

ë‹¹ì‹ ì€ ì´ ì •ë³´ë§Œìœ¼ë¡œ ì‚¬ìš©ìê°€ ì°¾ê³ ì í•˜ëŠ” ê¸°ì–µì„ ì¶”ë¡ í•´ì„œ ì•Œë ¤ì¤˜ì•¼ í•©ë‹ˆë‹¤.
"""

            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ë„ˆëŠ” ì‚¬ìš©ìì˜ ê¸°ì–µì„ ì¶”ë¡ í•˜ëŠ” ìƒë‹´ê°€ì•¼."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=1000,
            )

            gpt_reply = response.choices[0].message.content
            print("ğŸ§  GPT ì‘ë‹µ:", gpt_reply)

            return JsonResponse({"summary": gpt_reply})

        except Exception as e:
            print("âŒ ì˜ˆì™¸ ë°œìƒ:")
            traceback.print_exc()
            return JsonResponse({"error": str(e)}, status=500)

    return JsonResponse({"error": "POST ìš”ì²­ë§Œ í—ˆìš©ë©ë‹ˆë‹¤."}, status=405)
